---
title: "Regression Models"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: !expr bslib::bs_theme(bootswatch = "yeti", font_scale = 0.8)
    highlight: kate
    bg: "#202123"
    fg: "#B8BCC2"
    primary: "#EA80FC"
    base_font: !expr bslib::font_google("Grandstander")
    code_folding: show
    toc: true
    toc_depth: 2
    toc_float:
      collapse: true
      smooth_scroll: true
---


```{r message = F, warning = F}
library(tidyverse)
library(tidymodels)
library(themis)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5, message = F, warning = F)

theme_set(theme_light())

thematic::thematic_on()
```


# Predicting giant pumpkin weights
The goal is to predict the weight of giant pumpkins from other characteristics measured during a competition

```{r warning=FALSE, message=FALSE}

pumpkins_raw <- readr::read_csv("data/pumpkins_raw.csv")

pumpkins <-
  pumpkins_raw %>%
  separate(id, into = c("year", "type")) %>%
  mutate(across(c(year, weight_lbs, ott, place), parse_number)) %>%
  filter(type == "P") %>%
  select(weight_lbs, year, place, ott, gpc_site, country)

pumpkins
```


## Explore data  

Comparing volume/size of the pumpkin (measured via “over-the-top inches”) and weight.
```{r}
pumpkins %>%
  filter(ott > 20, ott < 1e3) %>%
  ggplot(aes(ott, weight_lbs, color = place)) +
  geom_point(alpha = 0.2, size = 1.1) +
  labs(x = "over-the-top inches", y = "weight (lbs)") +
  scale_color_viridis_c()
```

Has there been any shift in this relationship over time?
```{r}
pumpkins %>%
  filter(ott > 20, ott < 1e3) %>%
  ggplot(aes(ott, weight_lbs)) +
  geom_point(alpha = 0.2, size = 1.1, color = "gray60") +
  geom_smooth(aes(color = factor(year)),
    method = lm, formula = y ~ splines::bs(x, 3),
    se = FALSE, size = 1.5, alpha = 0.6
  ) +
  labs(x = "over-the-top inches", y = "weight (lbs)", color = NULL) +
  scale_color_viridis_d()
```

Which countries produced more or less massive pumpkins?
```{r}
pumpkins %>%
  mutate(
    country = fct_lump(country, n = 10),
    country = fct_reorder(country, weight_lbs)
  ) %>%
  ggplot(aes(country, weight_lbs, color = country)) +
  geom_boxplot(outlier.colour = NA) +
  geom_jitter(alpha = 0.1, width = 0.15) +
  labs(x = NULL, y = "weight (lbs)") +
  theme(legend.position = "none")
```


## Build models

- create training and testing sets
- create resampling folds from the *training* set

```{r}
set.seed(123)
pumpkin_split <- pumpkins %>%
  filter(ott > 20, ott < 1e3) %>%
  initial_split(strata = weight_lbs)

pumpkin_train <- training(pumpkin_split)
pumpkin_test <- testing(pumpkin_split)

set.seed(234)
pumpkin_folds <- vfold_cv(pumpkin_train, strata = weight_lbs)
pumpkin_folds
```

Creating recipes
```{r}
base_rec <-
  recipe(weight_lbs ~ ott + year + country + gpc_site,
    data = pumpkin_train
  ) %>%
  step_other(country, gpc_site, threshold = 0.02)

ind_rec <-
  base_rec %>%
  step_dummy(all_nominal_predictors())

spline_rec <-
  ind_rec %>%
  step_bs(ott)
```

Creating model specifications
```{r}
rf_spec <-
  rand_forest(trees = 1e3) %>%
  set_mode("regression") %>%
  set_engine("ranger")

mars_spec <-
  mars() %>%
  set_mode("regression") %>%
  set_engine("earth")

lm_spec <- linear_reg()
```

Combining the preprocessing and models together in a `workflow_set()`
```{r}
pumpkin_set <-
  workflow_set(
    list(base_rec, ind_rec, spline_rec),
    list(rf_spec, mars_spec, lm_spec),
    cross = FALSE
  )

pumpkin_set
```

## Evaluate models

```{r}
doParallel::registerDoParallel()
set.seed(2021)

pumpkin_rs <-
  workflow_map(
    pumpkin_set,
    "fit_resamples",
    resamples = pumpkin_folds
  )

pumpkin_rs
```

How did these three models compare?

```{r}
autoplot(pumpkin_rs)
```

```{r}
collect_metrics(pumpkin_rs)
```

Testing model on test set
```{r}
best_results <- pumpkin_rs %>% 
  extract_workflow_set_result("recipe_3_linear_reg") %>% 
  select_best(metric = "rmse")


final_wf <- pumpkin_rs %>% 
  extract_workflow("recipe_3_linear_reg") %>% 
  finalize_workflow(best_results)

last_fit <- final_wf %>% 
  last_fit(pumpkin_split)
```

```{r}
collect_metrics(last_fit)
```

Extracting the workflow we want to use and fit it to entire data
```{r}
final_fit <- fit(final_wf, pumpkins %>%
  filter(ott > 20, ott < 1e3))
```



```{r include=FALSE}
# Clear workspace
rm(list = ls())
gc()
```
  
  
  
# Predicting IKEA prices
The goal is to predict the price of IKEA furniture from other furniture characteristics like category and size.

```{r warning=FALSE, message=FALSE}

ikea <- read_csv("data/ikea.csv")
```

## Explore data  

How is the price related to the furniture dimensions?
```{r}
ikea %>%
  select(X1, price, depth:width) %>%
  pivot_longer(depth:width, names_to = "dim") %>%
  ggplot(aes(value, price, color = dim)) +
  geom_point(alpha = 0.4, show.legend = FALSE) +
  scale_y_log10() +
  facet_wrap(~dim, scales = "free_x") +
  labs(x = NULL)
```

```{r}
ikea_df <- ikea %>%
  select(price, name, category, depth, height, width) %>%
  mutate(price = log10(price)) %>% 
  mutate_at(c("name", "category"), snakecase::to_snake_case) %>% 
  mutate_if(is.character, factor)

ikea_df
```

## Build models  

```{r}
set.seed(123)
ikea_split <- initial_split(ikea_df, strata = price)
ikea_train <- training(ikea_split)
ikea_test <- testing(ikea_split)

set.seed(234)
ikea_folds <- bootstraps(ikea_train, strata = price)
ikea_folds
```

In your console, you can run the following code to produce a machine learning setup `usemodels::use_ranger(price ~ ., data = ikea_train)`. Make sure you install the `usemodels` package first.  

```{r}

ranger_recipe <-
  recipe(formula = price ~ ., data = ikea_train) %>%
  step_other(name, category, threshold = 0.01) %>%
  step_impute_knn(depth, height, width)

ranger_spec <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 1001) %>%
  set_mode("regression") %>%
  set_engine("ranger")

ranger_workflow <-
  workflow() %>%
  add_recipe(ranger_recipe) %>%
  add_model(ranger_spec)


set.seed(8577)
doParallel::registerDoParallel()
ranger_tune <-
  tune_grid(ranger_workflow,
    resamples = ikea_folds,
    grid = 5
  )

```

## Evaluate models

```{r}
show_best(ranger_tune, metric = "rmse")
```

```{r}
show_best(ranger_tune, metric = "rsq")
```

```{r}
autoplot(ranger_tune) +
  geom_line()
```

Selceting best model
```{r}
final_rf <- ranger_workflow %>%
  finalize_workflow(select_best(ranger_tune))

final_rf
```

Testing model on test set
```{r}
doParallel::registerDoParallel()

ikea_fit <- last_fit(final_rf, ikea_split)
collect_metrics(ikea_fit)
```

Fit it to entire data
```{r}
final_fit <- fit(final_rf, ikea_df)
```

You can save this fitted `final_wf` object to use later with new data, for example with `readr::write_rds()`.

